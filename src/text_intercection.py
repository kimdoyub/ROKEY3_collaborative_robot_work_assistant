import os
import rclpy
import pyaudio
import time
from rclpy.node import Node
from ament_index_python.packages import get_package_share_directory
from dotenv import load_dotenv
from datetime import datetime

from langchain.chains import LLMChain
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate

from od_msg.srv import SrvDepthPosition # custom service: string result --- bool success, string feedback
from od_msg.srv import Srvchat
from .MicController import MicController, MicConfig
from .wakeup_word import WakeupWord
from .STT import STT
from std_msgs.msg import Bool

# í™˜ê²½ ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°
package_path = get_package_share_directory("rokey")
load_dotenv(dotenv_path=os.path.join(package_path, "resource/.env"))
openai_api_key = os.getenv("OPENAI_API_KEY")

class VoiceServiceNode(Node):
    def __init__(self):
        super().__init__('voice_service_node')

        # LLM ì¤€ë¹„
        self.llm = ChatOpenAI(model="gpt-4o", temperature=0.3, openai_api_key=openai_api_key)
        self.classify_prompt = PromptTemplate(
            input_variables=["user_input"],
            template="""
        ë‹¤ìŒ ë¬¸ì¥ì˜ ì£¼ì œë¥¼ ë¶„ë¥˜í•´ì¤˜. 

        <ì£¼ì œ ë¦¬ìŠ¤íŠ¸>
        - meal, weather, cleanup

        <ì„ ì • ê·œì¹™>
        - ì»¤í”¼ë‚˜ ì‹ì‚¬, ì‹œë¦¬ì–¼ì— ê´€í•œ ëª…ë ¹ì´ë©´ mealì„ ì¶œë ¥í•´ì¤˜
        - ë‚ ì”¨ì— ê´€í•œ ì§ˆë¬¸ì´ë‚˜ ë…¸ë˜ ì¶”ì²œ, ì˜ìƒ ì¶”ì²œì— ê´€í•œ ì´ì•¼ê¸°ì´ë©´ weatherì„ ì¶œë ¥í•´ì¤˜
        - ì •ë¦¬ë‚˜ ì„¤ê±°ì§€ë¥¼ ëª…ë ¹í•˜ê±°ë‚˜ ì‘ë³„ ì¸ì‚¬ë¥¼ í•˜ë©´ cleanupë¥¼ ì¶œë ¥í•´ì¤˜

        <ì¶œë ¥ í˜•ì‹>
        - ì˜¤ì§ í•˜ë‚˜ì˜ ì£¼ì œë¥¼ ì„ íƒí•´ ì£¼ì œë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ì„¸ìš”(ì˜ˆ: meal)
        <ì‚¬ìš©ì ì…ë ¥>
        "{user_input}"  
        """
        )
        self.llm_enabled = True
        self.create_subscription(Bool, '/llm_activation', self.llm_activation_callback, 10)

        self.subject_to_service = {
            "meal": "/run_menu",
            "weather": "/run_weather",
            "setup": "/run_setup",
            # "bye": "/run_cleanup",
            "cleanup": "/run_cleanup"
        }

        # ë§ˆì´í¬ ì„¤ì • + wakeword
        self.mic_config = MicConfig(
            chunk=12000, rate=48000, channels=1, record_seconds=5,
            fmt=pyaudio.paInt16, device_index=10, buffer_size=24000
        )
        self.mic = MicController(config=self.mic_config)
        self.mic.open_stream()

        self.wakeup = WakeupWord(buffer_size=self.mic_config.buffer_size)
        self.wakeup.set_stream(self.mic.stream)

        self.stt = STT(openai_api_key=openai_api_key)
        self.get_logger().info("ğŸ¤ VoiceServiceNode initialized. Waiting for wakeword...")

        self.llm_chain_cache = {}

        self.run_loop()

    def llm_activation_callback(self, msg):
        if self.llm_enabled != msg.data:
            self.llm_enabled = msg.data
            self.get_logger().info(f"ğŸ” LLM í™œì„± ìƒíƒœ: {self.llm_enabled}")
            time.sleep(1)
        else:
            return

    def run_loop(self):
        while rclpy.ok():
            if not self.llm_enabled:
                rclpy.spin_once(self, timeout_sec=0.5)
                continue

                self.get_logger().info("ğŸ‘‚ ì›¨ì´í¬ì›Œë“œ ëŒ€ê¸° ì¤‘...")
            while not self.wakeup.is_wakeup():
                rclpy.spin_once(self, timeout_sec=0.1)

            self.get_logger().info("ğŸ¤ Wakeword ê°ì§€ë¨! ìŒì„± ì¸ì‹ ì‹œì‘")
            text_input = self.stt.speech2text()
            self.get_logger().info(f"ğŸ—£ ì‚¬ìš©ì ì…ë ¥: {text_input}")

            # subject ë¶„ë¥˜
            subject = self.classify_subject(text_input)
            result = self.generate_response(subject, text_input)

            self.get_logger().info(f"ğŸ§  ì£¼ì œ: {subject}")
            self.get_logger().info(f"ğŸ¤– ì‘ë‹µ: {result}")

            service_name = self.subject_to_service.get(subject)
            if not service_name:
                self.get_logger().error(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” subject: {subject}")
                continue

            self.call_subject_service(service_name, result)

    def classify_subject(self, user_input):
        chain = LLMChain(llm=self.llm, prompt=self.classify_prompt)
        result = chain.invoke({"user_input": user_input})
        return result["text"].strip().lower()

    def generate_response(self, subject, user_input):
        if subject in self.llm_chain_cache:
            chain = self.llm_chain_cache[subject]
        else:
            chain = self.build_chain_for_subject(subject,user_input)
            self.llm_chain_cache[subject] = chain

        now = datetime.now().strftime("%mì›” %dì¼, %p %Iì‹œ %Më¶„")
        variables = {"user_input": user_input, "now": now} if subject == "weather" else {"user_input": user_input}
        result = chain.invoke(variables)
        return result["text"].strip()

    def build_chain_for_subject(self, subject, user_input):
        if subject == "meal":
            system_prompt = '''
            ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ë¬¸ì¥ì—ì„œ **ìŒì‹ëª…**ê³¼ **ê´€ë ¨ í‚¤ì›Œë“œ**ë¥¼ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.  
            ëª¨ë“  ë¬¸ì¥ì€ ì•„ì¹¨ ì‹ì‚¬ì— ëŒ€í•œ ìš”ì²­ì…ë‹ˆë‹¤.

            <ëª©í‘œ>
            - ë¬¸ì¥ì—ì„œ ë“±ì¥í•˜ëŠ” **ìŒì‹ ì´ë¦„(ê³ ìœ ëª…ì‚¬ë‚˜ ì¼ë°˜ìŒì‹)** ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
            - ìŒì‹ê³¼ ì—°ê²°ëœ **ë§›, ì¢…ë¥˜, ë¸Œëœë“œ ë“± íŠ¹ì§• í‚¤ì›Œë“œ**ë„ í•¨ê»˜ ì¶”ì¶œí•©ë‹ˆë‹¤.

            <ì¶œë ¥ í˜•ì‹>
            - ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”: [ìŒì‹1 ìŒì‹2 ... / í‚¤ì›Œë“œ1 í‚¤ì›Œë“œ2 ...]
            - ìŒì‹ê³¼ í‚¤ì›Œë“œëŠ” ê°ê° ê³µë°±ìœ¼ë¡œ êµ¬ë¶„
            - ìˆœì„œëŠ” ë¬¸ì¥ì—ì„œ ë“±ì¥í•œ ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ë”°ë¦…ë‹ˆë‹¤
            - ìŒì‹ ì´ë¦„ì´ ì—†ê±°ë‚˜ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°ëŠ” ê³µë°± ì—†ì´ ë¹„ìš°ê³ , í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ '/' ë’¤ë¥¼ ë¹„ì›Œë‘¡ë‹ˆë‹¤

            <ì˜ˆì‹œ>
            - ì…ë ¥: "ê³ ì†Œí•œ ì»¤í”¼ë¡œ ë¶€íƒí•´"  
            ì¶œë ¥: ì»¤í”¼ / ê³ ì†Œí•œ

            - ì…ë ¥: "ì´ˆì½” ì‹œë¦¬ì–¼ë¡œ ì¤˜"  
            ì¶œë ¥: ì‹œë¦¬ì–¼ / ì´ˆì½”

            - ì…ë ¥: "ë‹¨ ì»¤í”¼ì™€ ì½˜í”„ë¡œìŠ¤íŠ¸ë¡œ ì¤˜"  
            ì¶œë ¥: ì»¤í”¼ ì‹œë¦¬ì–¼ / ë‹¨ë§› ì½˜í”„ë¡œìŠ¤íŠ¸

            - ì…ë ¥: "ë‹¬ë‹¬í•œ ì»¤í”¼ ì¤˜"  
            ì¶œë ¥: ì»¤í”¼ / ë‹¨ë§› 

            - ì…ë ¥: "ìº¬ë¼ë©œë§› ì»¤í”¼ì™€ ì´ˆì½”ë§› ì‹œë¦¬ì–¼ ì¤˜"  
            ì¶œë ¥: ì»¤í”¼ ì‹œë¦¬ì–¼ / ì¹´ë¼ë©œ ì´ˆì½”


            - ì…ë ¥: "ì˜¤ëŠ˜ì€ ê·¸ë ˆë†€ë¼ ë¨¹ì„ë ˆ"  
            ì¶œë ¥: ì‹œë¦¬ì–¼ / ê·¸ë ˆë†€ë¼

            <ì‚¬ìš©ì ì…ë ¥>
            "{user_input}"
            '''
            chat_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_prompt),
            HumanMessagePromptTemplate.from_template("{user_input}")
            ])

        elif subject == "weather":
            now = datetime.now().strftime("%mì›” %dì¼, %p %Iì‹œ %Më¶„")
            system_prompt = '''
            í˜„ì¬ ì‹œê°„ì€ {now}ì…ë‹ˆë‹¤.  
            ë‹¹ì‹ ì€ ê¸°ìƒìºìŠ¤í„° ì—­í• ì„ ë§¡ì€ ì¸ê³µì§€ëŠ¥ì…ë‹ˆë‹¤.  
            ì‚¬ìš©ìì˜ ë¬¸ì¥ì—ì„œ ì˜¤ëŠ˜ì˜ ë‚ ì”¨ì™€ ê´€ë ¨ëœ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´, ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ì •í™•í•œ ì¼ê¸°ì˜ˆë³´ì™€ ì ì ˆí•œ ì˜ìƒ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”.

            ---

            <ëª©í‘œ>
            1. ì˜¤ëŠ˜ì˜ ë‚ ì”¨ë¥¼ ì˜ˆë³´ í˜•ì‹ìœ¼ë¡œ ì•ˆë‚´í•˜ì„¸ìš”.  
            2. ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì§€ì—­ê³¼ ì‹œê°„ëŒ€ê°€ ëª…ì‹œë˜ì—ˆìœ¼ë©´ ê·¸ì— ë§ê²Œ ë³´ì •ëœ ì˜ˆë³´ë¥¼ ìƒì„±í•˜ì„¸ìš”.  
            3. ë‚ ì”¨ ì„¤ëª… í›„, ê¸°ì˜¨Â·ìŠµë„Â·ë°”ëŒ ë“±ì„ ê³ ë ¤í•˜ì—¬ **ì˜ìƒ ì¶”ì²œ ë¬¸ì¥ì„ ë°˜ë“œì‹œ í¬í•¨**í•˜ì„¸ìš”.

            ---

            <ë‚ ì”¨ ì •ë³´ êµ¬ì„± ìˆœì„œ>
            1. ë‚ ì§œì™€ í˜„ì¬ ì‹œê°„
            2. í•˜ëŠ˜ ìƒíƒœ (ë§‘ìŒ, íë¦¼, ë¹„ ë“±)
            3. ê¸°ì˜¨ ì •ë³´ (ìµœê³ /ìµœì € ê¸°ì˜¨)
            4. ë°”ëŒ ë°©í–¥ ë° ì„¸ê¸°
            5. ìŠµë„ì™€ ë¯¸ì„¸ë¨¼ì§€ ì •ë³´
            6. ì˜ìƒ ì¶”ì²œ (ex. â€œì–‡ì€ ê²‰ì˜· ì¶”ì²œë“œë¦½ë‹ˆë‹¤â€, â€œìš°ì‚° ê¼­ ì±™ê¸°ì„¸ìš”â€)

            ---

            <íŠ¹ìˆ˜ ê·œì¹™>
            - ì‘ë‹µì€ **ê¸°ìƒìºìŠ¤í„° ìŠ¤íƒ€ì¼**ë¡œ ì¹œì ˆí•˜ê³  ë‹¨ì •í•˜ê²Œ ì„œìˆ í•  ê²ƒ
            - **ì‚¬ìš©ì ì§ˆë¬¸ì´ ë§¤ìš° ì§§ë”ë¼ë„** ìœ„ì˜ ì „ì²´ ì–‘ì‹ì„ ëª¨ë‘ ì±„ì›Œì„œ ì‘ë‹µí•  ê²ƒ
            - **ë¹„ê°€ ì˜¤ë©´ ìš°ì‚°**, **ë”ìš°ë©´ ì–‡ì€ ì˜·**, **ìŒ€ìŒ€í•˜ë©´ ê¸´íŒ”** ë“± **êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì˜ìƒ ì¡°ì–¸**ì„ ë°˜ë“œì‹œ í¬í•¨í•  ê²ƒ
            - ì§€ì—­ ì–¸ê¸‰ì´ ì—†ìœ¼ë©´ **ì‚¬ìš©ìì˜ í˜„ì¬ ìœ„ì¹˜**ë¡œ ê°€ì •
            - ì‹¤ì œ ê¸°ìƒ ì •ë³´ ëŒ€ì‹  **ìƒí™©ì— ë§ëŠ” ê°€ìƒì˜ ì˜ˆë³´ë¥¼ ìƒì„±**í•´ë„ ë¬´ë°©

            ---

            <ì˜ˆì‹œ>

            - ì…ë ¥: "ì˜¤ëŠ˜ ë‚ ì”¨ ë­ì•¼?"  
            ì¶œë ¥:
            6ì›” 26ì¼, í˜„ì¬ ì‹œê°„: ì˜¤í›„ 2ì‹œ 30ë¶„ ë‚ ì”¨ì…ë‹ˆë‹¤.  
            ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ëŒ€ì²´ë¡œ ë§‘ê² ìŠµë‹ˆë‹¤. ë‚® ìµœê³  ê¸°ì˜¨ì€ 29Â°C, ìµœì € ê¸°ì˜¨ì€ 20Â°Cë¡œ ì˜ˆìƒë©ë‹ˆë‹¤.  
            ë°”ëŒì€ ë‚¨ì„œí’ì´ ì´ˆì† 2~4më¡œ ë¶ˆê² ìœ¼ë©°, ë¯¸ì„¸ë¨¼ì§€ ë†ë„ëŠ” ë³´í†µ ìˆ˜ì¤€ì…ë‹ˆë‹¤.  
            ìŠµë„ëŠ” ì•½ 60%ë¡œ ì•¼ì™¸ í™œë™ì— í° ë¬´ë¦¬ëŠ” ì—†ê² ìŠµë‹ˆë‹¤.  
            ë¥ì§€ë§Œ ë°”ëŒì´ ë¶ˆì–´ í†µê¸°ì„± ì¢‹ì€ ì–‡ì€ ì˜·ì°¨ë¦¼ì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.

            - ì…ë ¥: "ì„œìš¸ ë‚ ì”¨ ì¢€ ì•Œë ¤ì¤˜"  
            ì¶œë ¥:
            6ì›” 26ì¼, í˜„ì¬ ì‹œê°„: ì˜¤í›„ 2ì‹œ 30ë¶„, ì„œìš¸ì˜ ë‚ ì”¨ì…ë‹ˆë‹¤.  
            ì„œìš¸ì€ íë¦¬ê³  ì˜¤í›„ë¶€í„° ë¹„ê°€ ë‚´ë¦´ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.  
            ë‚® ìµœê³  ê¸°ì˜¨ì€ 24Â°C, ìµœì € ê¸°ì˜¨ì€ 19Â°Cì…ë‹ˆë‹¤.  
            ë¶ë™í’ì´ ì´ˆì† 3~5më¡œ ë¶ˆê² ê³ , ìŠµë„ëŠ” 85%ë¡œ ë‹¤ì†Œ ë†’ì€ í¸ì…ë‹ˆë‹¤.  
            ìš°ì‚°ê³¼ ë°©ìˆ˜ ì‹ ë°œì„ ì¤€ë¹„í•˜ì‹œëŠ” ê²ƒì´ ì¢‹ê² ìŠµë‹ˆë‹¤.

            ---

            <ì‚¬ìš©ì ì…ë ¥>  
            "{user_input}"
            '''
            chat_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_prompt),
            HumanMessagePromptTemplate.from_template("{user_input}")
            ])

        elif subject == "cleanup":
            system_prompt = '''
            ë‹¹ì‹ ì€ ì§‘ì„ ì§€í‚¤ëŠ” ì¸ê³µì§€ëŠ¥ ë¹„ì„œì…ë‹ˆë‹¤.  
            ì‚¬ìš©ìì˜ ë¬¸ì¥ì´ ì™¸ì¶œ ì¸ì‚¬ ë˜ëŠ” ì²­ì†Œ/ì •ë¦¬ ëª…ë ¹ì¼ ê²½ìš°, ì¹œì ˆí•˜ê²Œ ì‘ë³„ ì¸ì‚¬ë¥¼ í•´ì£¼ì„¸ìš”.

            ---

            <ëª©í‘œ>
            - ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°, ì‘ë³„ ì¸ì‚¬ë¡œ ì‘ë‹µí•˜ì„¸ìš”:  
            - ì‚¬ìš©ìê°€ ì™¸ì¶œì„ ì•”ì‹œí•˜ëŠ” ë§ ("ë‚˜ ë‚˜ê°„ë‹¤", "ì§‘ ì˜ ì§€ì¼œ", "ì´ë”° ì˜¬ê²Œ", "ì˜ ìˆì–´")  
            - ì‚¬ìš©ìê°€ ì •ë¦¬ ê´€ë ¨ ëª…ë ¹ì„ ë‚´ë¦¬ëŠ” ê²½ìš° ("ì²­ì†Œí•´", "ì •ë¦¬í•´ì¤˜", "ì„¤ê±°ì§€ í•´")  

            - ì‘ë³„ ì¸ì‚¬ëŠ” **ì •ì¤‘í•˜ê³  ê³µì†í•œ ë¬¸ì¥**ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.  
            - ë‹¨ë‹µí˜•ìœ¼ë¡œ ëë‚´ì§€ ë§ê³  **ì§§ì€ ì‘ì›ì´ë‚˜ ë°°ì›… ë¬¸ì¥**ì„ í•¨ê»˜ ë¶™ì´ë©´ ì¢‹ìŠµë‹ˆë‹¤.

            ---

            <ì¶œë ¥ í˜•ì‹>
            - ê¸°ë³¸ ì‘ë³„ ë¬¸ì¥ì€ ë°˜ë“œì‹œ í¬í•¨: `ì•ˆë…•íˆê°€ì„¸ìš”.`
            - í•„ìš”í•˜ë©´ ë§ë¶™ì¼ ìˆ˜ ìˆìŒ: `ì˜ ë‹¤ë…€ì˜¤ì„¸ìš”.`, `ì œê°€ ì§‘ ì˜ ì§€í‚¬ê²Œìš”.`, `ê¹¨ë—í•˜ê²Œ ì²­ì†Œí•´ë‘˜ê²Œìš”.` ë“±
            - ì¶œë ¥ì€ í•œ ë¬¸ë‹¨(1~2ë¬¸ì¥) ì •ë„

            ---

            <ì˜ˆì‹œ>
            - ì…ë ¥: "ë‚˜ ë‚˜ê°„ë‹¤"  
            ì¶œë ¥: ì•ˆë…•íˆê°€ì„¸ìš”. ì œê°€ ì§‘ ì˜ ì§€í‚¬ê²Œìš”.

            - ì…ë ¥: "ì²­ì†Œ ì¢€ í•´ì¤˜"  
            ì¶œë ¥: ì•ˆë…•íˆê°€ì„¸ìš”. ë‹¤ë…€ì˜¤ì‹œëŠ” ë™ì•ˆ ê¹¨ë—í•˜ê²Œ ì •ë¦¬í•´ë‘˜ê²Œìš”.

            - ì…ë ¥: "ì§‘ ì˜ ì§€ì¼œ"  
            ì¶œë ¥: ì•ˆë…•íˆê°€ì„¸ìš”. ê±±ì • ë§ˆì‹œê³  ë‹¤ë…€ì˜¤ì„¸ìš”!

            - ì…ë ¥: "ì„¤ê±°ì§€í•˜ê³  ë‚˜ê°„ë‹¤"  
            ì¶œë ¥: ì•ˆë…•íˆê°€ì„¸ìš”. ì œê°€ ë‚˜ë¨¸ì§€ ì •ë¦¬ê¹Œì§€ ë„ì™€ë“œë¦´ê²Œìš”.

            ---

            <ì‚¬ìš©ì ì…ë ¥>
            "{user_input}"

        '''
            chat_prompt = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(system_prompt),
            HumanMessagePromptTemplate.from_template("{user_input}")
            ])

        else: 
            return "ì£„ì†¡í•´ìš”. ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”."
        
        return LLMChain(llm=self.llm, prompt=chat_prompt)

    def call_subject_service(self, service_name, result):
        client = self.create_client(Srvchat, service_name)
        while not client.wait_for_service(timeout_sec=1.0):
            self.get_logger().warn(f"{service_name} ì„œë¹„ìŠ¤ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")

        request = Srvchat.Request()
        request.result = result

        future = client.call_async(request)
        rclpy.spin_until_future_complete(self, future)
        if future.result():
            res = future.result()
            self.get_logger().info(f"âœ… ì„œë¹„ìŠ¤ ì™„ë£Œ: {res.feedback}")
        else:
            self.get_logger().error("âŒ ì„œë¹„ìŠ¤ í˜¸ì¶œ ì‹¤íŒ¨")

def main():
    rclpy.init()
    node = VoiceServiceNode()
    rclpy.shutdown()

if __name__ == '__main__':
    main()
